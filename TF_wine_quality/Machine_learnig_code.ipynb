{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wine quality prediction with TensorFlow. Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code Created by Luis Enrique Acevedo Galicia\n",
    "\n",
    "Date: 2019-10-03\n",
    "\n",
    "Here, I present a simple and easy way to create a machine learning algorithm, which is able to predict wine quality. There are 11 inputs and one target. In this part, only the Machine learnig analysis (RNN) with Tensorflow is presented. The prepicessing data can be found in part 1.\n",
    "\n",
    "The data set was obtained from https://www.kaggle.com/vishalyo990/prediction-of-quality-of-wine/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Divide all data in batches\n",
    "class Batch_data_reader():\n",
    "    def __init__(self,DataSet, size_batch = None):\n",
    "        npz = np.load('WINE_data_{0}.npz'.format(DataSet))\n",
    "        self.inputs = npz['inputs'].astype(np.float)\n",
    "        self.targets = npz['targets'].astype(np.int)\n",
    "        #count the batch\n",
    "        if size_batch is None:\n",
    "            self.size_batch = self.inputs.shape[0]\n",
    "        else:\n",
    "            self.size_batch = size_batch\n",
    "        self.batch_current = 0\n",
    "        self.batch_count = self.inputs.shape[0]//self.size_batch\n",
    "    #load next batch\n",
    "    def __next__(self):\n",
    "        if self.batch_current >= self.batch_count:\n",
    "            self.batch_current = 0\n",
    "            raise StopIteration()\n",
    "        slice_batch = slice(self.batch_current*self.size_batch, (self.batch_current+1)*self.size_batch)\n",
    "        batch_inputs = self.inputs[slice_batch]\n",
    "        batch_targets = self.targets[slice_batch]\n",
    "        self.batch_current += 1\n",
    "        \n",
    "\n",
    "        \n",
    "        return batch_inputs, batch_targets\n",
    "    #this part allows the class to iterate \n",
    "    def __iter__(self):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1. Training loss: 10.383. Validation loss: 0.640. Validation accuracy: 88.83%\n",
      "Epoch 2. Training loss: 0.608. Validation loss: 0.533. Validation accuracy: 89.66%\n",
      "Epoch 3. Training loss: 0.589. Validation loss: 0.525. Validation accuracy: 89.81%\n",
      "Epoch 4. Training loss: 0.584. Validation loss: 0.518. Validation accuracy: 89.90%\n",
      "Epoch 5. Training loss: 0.577. Validation loss: 0.509. Validation accuracy: 90.04%\n",
      "Epoch 6. Training loss: 0.570. Validation loss: 0.501. Validation accuracy: 90.22%\n",
      "Epoch 7. Training loss: 0.564. Validation loss: 0.493. Validation accuracy: 90.34%\n",
      "Epoch 8. Training loss: 0.558. Validation loss: 0.485. Validation accuracy: 90.44%\n",
      "Epoch 9. Training loss: 0.552. Validation loss: 0.477. Validation accuracy: 90.54%\n",
      "Epoch 10. Training loss: 0.546. Validation loss: 0.468. Validation accuracy: 90.65%\n",
      "Epoch 11. Training loss: 0.539. Validation loss: 0.459. Validation accuracy: 90.77%\n",
      "Epoch 12. Training loss: 0.530. Validation loss: 0.449. Validation accuracy: 90.90%\n",
      "Epoch 13. Training loss: 0.522. Validation loss: 0.440. Validation accuracy: 91.02%\n",
      "Epoch 14. Training loss: 0.513. Validation loss: 0.431. Validation accuracy: 91.13%\n",
      "Epoch 15. Training loss: 0.505. Validation loss: 0.423. Validation accuracy: 91.23%\n",
      "Epoch 16. Training loss: 0.498. Validation loss: 0.415. Validation accuracy: 91.30%\n",
      "Epoch 17. Training loss: 0.491. Validation loss: 0.408. Validation accuracy: 91.37%\n",
      "Epoch 18. Training loss: 0.484. Validation loss: 0.405. Validation accuracy: 91.41%\n",
      "Epoch 19. Training loss: 0.478. Validation loss: 0.406. Validation accuracy: 91.45%\n",
      "End of training.\n"
     ]
    }
   ],
   "source": [
    "#define inputs and targets size\n",
    "input_size = 11\n",
    "output_size = 1\n",
    "# hidden layer size\n",
    "hidden_layer_size = 50\n",
    "\n",
    "# Reset the default graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Placeholders\n",
    "inputs = tf.placeholder(tf.float32, [None, input_size])\n",
    "targets = tf.placeholder(tf.float32, [None, output_size])\n",
    "\n",
    "# The net will contain 3 hidden layers\n",
    "\n",
    "\n",
    "weights_1 = tf.get_variable(\"weights_1\", [input_size, hidden_layer_size])\n",
    "biases_1 = tf.get_variable(\"biases_1\", [hidden_layer_size])\n",
    "outputs_1 = tf.nn.relu(tf.matmul(inputs, weights_1) + biases_1)\n",
    "\n",
    "weights_2 = tf.get_variable(\"weights_2\", [hidden_layer_size, hidden_layer_size])\n",
    "biases_2 = tf.get_variable(\"biases_2\", [hidden_layer_size])\n",
    "outputs_2 = tf.nn.relu(tf.matmul(outputs_1, weights_2) + biases_2)\n",
    "\n",
    "weights_3 = tf.get_variable(\"weights_3\", [hidden_layer_size, hidden_layer_size])\n",
    "biases_3 = tf.get_variable(\"biases_3\", [hidden_layer_size])\n",
    "outputs_3 = tf.nn.tanh(tf.matmul(outputs_2, weights_3) + biases_3)\n",
    "\n",
    "weights_4 = tf.get_variable(\"weights_4\", [hidden_layer_size, output_size])\n",
    "biases_4 = tf.get_variable(\"biases_4\", [output_size])\n",
    "# The softmax activation into the loss\n",
    "outputs = tf.matmul(outputs_3, weights_4) + biases_4\n",
    "\n",
    "\n",
    "\n",
    "# Use the softmax cross entropy loss with logits\n",
    "#loss = tf.nn.softmax_cross_entropy_with_logits(logits=outputs, labels=targets)\n",
    "#mean_loss = tf.reduce_mean(loss)\n",
    "mean_loss = tf.reduce_mean(tf.squared_difference(outputs, targets))\n",
    "\n",
    "\n",
    "#(Vtarget - Voutput)/Vtarget X 100\n",
    "out_equals_target = tf.abs(tf.math.divide(tf.subtract(targets,outputs), targets))\n",
    "#out_equals_target = tf.equal(tf.argmax(outputs, 1), tf.argmax(targets, 1))\n",
    "accuracy = tf.reduce_mean(out_equals_target)\n",
    "#accuracy = tf.reduce_mean(tf.cast(out_equals_target, tf.float32))\n",
    "\n",
    "\n",
    "\n",
    "# Optimize with Adam\n",
    "optimize = tf.train.AdamOptimizer(learning_rate=0.0001).minimize(mean_loss)\n",
    "\n",
    "# Create a session\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "# Initialize the variables\n",
    "initializer = tf.global_variables_initializer()\n",
    "sess.run(initializer)\n",
    "\n",
    "# Choose the batch size\n",
    "batch_size = 3\n",
    "\n",
    "# Set early stopping mechanisms\n",
    "max_epochs = 100\n",
    "prev_validation_loss = 9999999.\n",
    "\n",
    "\n",
    "train_data = Batch_data_reader('Train', batch_size)\n",
    "validation_data = Batch_data_reader('Valid')\n",
    "\n",
    "# Create the loop for epochs \n",
    "for epoch_counter in range(max_epochs):\n",
    "    \n",
    "    # initialize the epoch loss to 0\n",
    "    curr_epoch_loss = 0.\n",
    "    \n",
    "    # Iterations over the batched training data \n",
    "    for input_batch, target_batch in train_data:\n",
    "        _, batch_loss = sess.run([optimize, mean_loss], \n",
    "            feed_dict={inputs: input_batch, targets: target_batch})\n",
    "        \n",
    "        #Get record of the batch loss\n",
    "        curr_epoch_loss += batch_loss\n",
    "    \n",
    "    # The mean curr_epoch_loss\n",
    "    \n",
    "    curr_epoch_loss /= train_data.batch_count\n",
    "    \n",
    "    #Validation:\n",
    "    \n",
    "    # Validation loss and accuracy for the epoch to zero\n",
    "    validation_loss = 0.\n",
    "    validation_accuracy = 0.\n",
    "    \n",
    "    # In this case the batch size is equal to the data set\n",
    "    \n",
    "    for input_batch, target_batch in validation_data:\n",
    "        validation_loss, validation_accuracy = sess.run([mean_loss, accuracy],\n",
    "            feed_dict={inputs: input_batch, targets: target_batch})\n",
    "    \n",
    "    # Print results and statistics for the current epoch\n",
    "    print('Epoch '+str(epoch_counter+1)+\n",
    "          '. Training loss: '+'{0:.3f}'.format(curr_epoch_loss)+\n",
    "          '. Validation loss: '+'{0:.3f}'.format(validation_loss)+\n",
    "          '. Validation accuracy: '+'{0:.2f}'.format((1-validation_accuracy )* 100.)+'%')\n",
    "    \n",
    "    # An early stop (only if validation loss is increasing)\n",
    "    if validation_loss > prev_validation_loss:\n",
    "        break\n",
    "        \n",
    "    #keep epochs validation loss.\n",
    "    prev_validation_loss = validation_loss\n",
    "    \n",
    "print('End of training.')\n",
    "#print(curr_loss)\n",
    "TF_w1=sess.run(weights_1)\n",
    "TF_b1=sess.run(biases_1)\n",
    "TF_w2=sess.run(weights_2)\n",
    "TF_b2=sess.run(biases_2)\n",
    "TF_w3=sess.run(weights_3)\n",
    "TF_b3=sess.run(biases_3)\n",
    "TF_w4=sess.run(weights_4)\n",
    "TF_b4=sess.run(biases_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 90.15363%\n"
     ]
    }
   ],
   "source": [
    "# Load the test data in batches\n",
    "test_data = Batch_data_reader('Test')\n",
    "#Obtain the test accuracy\n",
    "for inputs_batch, targets_batch in test_data:\n",
    "    test_accuracy = sess.run([accuracy],\n",
    "                     feed_dict={inputs: inputs_batch, targets: targets_batch})\n",
    "\n",
    "#convert value of first position to get the percentage of accuracy\n",
    "test_accuracy_percent = (1-test_accuracy[0]) * 100.\n",
    "\n",
    "# Print accuracy\n",
    "print('Test accuracy: '+'{0:.5f}'.format(test_accuracy_percent)+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fixed acidity :7.8\n",
      "volatile acidity :0.76\n",
      "citric acid :0.04\n",
      "residual sugar :2.3\n",
      "chlorides :0.092\n",
      "free sulfur dioxide :15\n",
      "total sulfur dioxide :54\n",
      "density :0.997\n",
      "pH :3.26\n",
      "sulphates :0.65\n",
      "alcohol :9.8\n",
      "The quality of your wine is  [[5.]]\n"
     ]
    }
   ],
   "source": [
    "input1 = []\n",
    "n1 = input(\"fixed acidity :\")\n",
    "input1.append(float(n1))\n",
    "n2 = input(\"volatile acidity :\")\n",
    "input1.append(float(n2))\n",
    "n3 = input(\"citric acid :\")\n",
    "input1.append(float(n3))\n",
    "n4 = input(\"residual sugar :\")\n",
    "input1.append(float(n4))\n",
    "n5 = input(\"chlorides :\")\n",
    "input1.append(float(n5))\n",
    "n6 = input(\"free sulfur dioxide :\")\n",
    "input1.append(float(n6))\n",
    "n7 = input(\"total sulfur dioxide :\")\n",
    "input1.append(float(n7))\n",
    "n8 = input(\"density :\")\n",
    "input1.append(float(n8))\n",
    "n9 = input(\"pH :\")\n",
    "input1.append(float(n9))\n",
    "n10 = input(\"sulphates :\")\n",
    "input1.append(float(n10))\n",
    "n11 = input(\"alcohol :\")\n",
    "input1.append(float(n11))\n",
    "input1=np.mat(input1)\n",
    "input1 = input1.tolist()\n",
    "#input1=[[7.8,0.76,0.04,2.3,0.092,15,54,0.997,3.26,0.65,9.8]]\n",
    "Out1 = tf.nn.relu(tf.matmul(input1, TF_w1) + TF_b1)\n",
    "out2 = tf.nn.relu(tf.matmul(Out1, TF_w2) + TF_b2)\n",
    "out3 = tf.nn.tanh(tf.matmul(out2, TF_w3) + TF_b3)\n",
    "out4 = tf.round(tf.matmul(out3, TF_w4) + TF_b4)\n",
    "RT=sess.run(out4)\n",
    "print('The quality of your wine is ', RT)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
